# 超大文件HTTP断点续传

>用分片文件上传方式来实现大文件上传，方法是将文件切成小片，  
例如4MB一个片段，服务器端每次接收一小片文件保存成一个临时文件，等待所有片段传输完毕后，再执行合并。  
如果原始文件足够小，这种方式是可以的，但一旦文件有几百兆或者几个GB或者几十个GB，  
则合并文件的时间会足够长，常常导致浏览器超时或服务器阻塞。

浏览器在上传某个文件时候，先给这个文件生成一个HASH值，必须在浏览器端生成这个HASH值。

不能单循地依据文件名来查询文件上传记录，文件名的重复性很大，  

文件名 + 文件尺寸组成的值重复性缩小，如果再加上文件修改时间，则重复性进一步缩小，如果再加上一个浏览器的 ID可以进一步缩小重复性冲突。  

最好的HASH值的计算方法是用文件的内容进行MD5计算，但计算量极大，过多的耗时会影响上传的体验。

基于上述理由，我的HASH值计算思路如下：

首先给浏览器赋予一个ID，这个ID保存在Cookie里；
浏览器的 ID+ 文件的修改时间 + 文件名 + 文件尺寸 的结果进行MD5来计算一个文件的HASH值；
浏览器的ID 是系统在浏览器访问文件上传站点时自动给浏览器授予的。




## 什么是断点续传
- 1.定义：

可以从下载或上传断开点继续开始传输，就叫断点续传。

- 2.核心实现原理：
```
i.RandomAccessFile(文件任意位置保存) 

方法seek():可以移动到保存文件任意位置，在该位置发生下一个读取或写入操作

ii.HttpURLConnection.setRequestProperty()(任意位置请求返回剩余文件)

HttpURLConnection.setRequestProperty(“Range”, “bytes=” + start + “-” + end)
```




## 参考
- [fex-team/webuploader](https://github.com/fex-team/webuploader/)
- [web-uploader](https://github.com/devin87/web-uploader)
- [HTTP文件断点续传原理解析(源码)](https://blog.csdn.net/Awenyini/article/details/77898704)
- [HTTP文件上传服务器-支持超大文件HTTP断点续传的实现办法](https://blog.csdn.net/ababab12345/article/details/80490621 )

- [plupload](https://github.com/moxiecode/plupload)
- [resumable.js](https://github.com/23/resumable.js)
